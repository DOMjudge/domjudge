<!doctype linuxdoc system [
<!ENTITY % admin "INCLUDE">
<!ENTITY % judge "IGNORE">
<!ENTITY domjudgeoverview SYSTEM "../domjudge-overview-inc.sgml">
]>
<!--
 DOMjudge Administrator's Manual
 This manual is part of the DOMjudge Programming Contest Jury System
 and licensed under the GNU GPL. See README and COPYING for details.
-->
<report>

<title>DOMjudge Administrator's Manual
<author>by the DOMjudge team
<!--
 This is some comment character magic to circumvent problems
 with an unexpanded git archive $Format$ keyword.
 $Format: -%x2d%x3e
<date>%aD
%x3c!%x2d- $ -->

<abstract>
This document provides information about DOMjudge installation,
configuration and operation for the DOMjudge administrator. A separate
manual is available for teams and for jury members.

<!-- $Format: -%x2d%x3e
Document version: %h
%x3c!%x2d- $ -->
</abstract>

<toc>

&domjudgeoverview;

<chapt>Contest planning<label id="contest_planning">
<p>

<sect>Contest hardware
<p>

DOMjudge discerns the following kinds of hosts:
<descrip>
<tag>Team computer</tag>
       Workstation for a team, where they develop their
       solutions and from which they submit them to the jury system.
       The only part of DOMjudge that runs here is the optional
       command line submit client; all other interaction by teams is
       done with a browser via the web interface.
<tag>DOMjudge server</tag>
       A host that receives the submissions, runs the
       database and serves the web pages. This host will run the
       nginx or Apache webserver and MySQL or MariaDB database.
       Also called <em>domserver</em> for brevity.
<tag>Judgehosts</tag>
       A number of hosts, at least one, that will retrieve
       submitted solutions from the DOMjudge server, compile and run
       them and send the results back to the server.
       They will run the <tt>judgedaemon</tt> from DOMjudge.
<tag>Jury / admin workstations</tag>
       The jury members (persons) that want to monitor the contest need
       just any workstation with a web browser to access the web interface.
       No DOMjudge software runs on these machines.
</descrip>

One (virtual) machine is required to run the DOMserver. The minimum amount of
judgehosts is also one, but preferably more: depending on configured timeouts,
judging one solution can tie up a judgehost for several minutes, and if there's
a problem with one judgehost it can be resolved while judging continues on the
others.

As a rule of thumb, we recommend one judgehost per 20 teams.

However, overprovisioning does not hurt: DOMjudge scales easily in the
number of judgehosts, so if hardware is available, by all means use it. But
running a contest with fewer machines will equally work well, only the waiting
time for teams to receive an answer may increase.

Each judgehost should be a dedicated (virtual) machine that performs no other
tasks. For example, although running a judgehost on the same machine as the
domserver is possible, it's not recommended except for testing purposes.
Judgehosts should also not double as local workstations for jury members.
Having all judgehosts be of uniform hardware configuration helps in creating a fair,
reproducible setup; in the ideal case they are run on the same type of machines
that the teams use.

DOMjudge supports running multiple judgedaemons in parallel on a
single judgehost machine. This might be useful on multi-core machines.
Note that although each judgedaemon process can be bound to one single
CPU core (using Linux cgroups), shared use of other resources such as
disk I/O might still have a minor effect on run times. For more
details on using this, see the section <ref id="optionalfeatures"
name="Installation: optional features">.

<sect>Requirements
<label id="install_config:requirements">
<p>

<sect1>System requirements
<p>

The requirements for the deployment of DOMjudge are:

<itemize>
<item> Computers for the domserver and judgehosts must run Linux (or
       the domserver possibly a Unix variant). This software has been
       developed mostly under Debian GNU/Linux, and the manual adds
       some specific hints for that, which also apply to Debian
       derivative distributions like Ubuntu. DOMjudge has also been
       tested under RedHat-like Linux distributions. We try to adhere
       to POSIX standards, but especially the judgehost security
       solution is Linux-specific.

<item> (Local) root access on the domserver and judgehosts for configuring sudo,
       installing some files with restricted permissions
       and for (un)mounting the proc file system.
       See <ref id="security:rootprivs" name="Security: root privileges">
       for more details.

<item> A TCP/IP network which connects all DOMjudge and team computers.
       Extra network security which restricts internet access and
       access to other services (ssh, mail, talk, etc..) is advisable,
       but not provided by this software, see <ref
       id="security:external" name="Security: external security"> for
       more details. All network-based interactions are done over HTTP
       or HTTPS (tcp port 80 or 443):
  <itemize>
  <item> HTTP traffic from teams, the public and jury to the web server.
  <item> The judgehosts connect to the DOMjudge API on the webserver over HTTP(S).
  <item> The `submit' command line client connects to API on the web server also
         via HTTP(S).
  </itemize>
       When using the "IP Address" authentication scheme, then each team
       computer needs to have a unique IP address from the view of the
       DOMjudge server, see <ref id="install_config:authmethods"
       name="Authentication Methods"> for more details.
</itemize>


<sect1>Software requirements
<p>

The following software is required for running DOMjudge.
<itemize>
<item> For every supported programming language a compiler is needed;
       preferably one that can generate statically linked stand-alone
       executables.

<item> nginx web server with PHP FPM or Apache web server with mod_rewrite.

<item> PHP &gt;= 7.0, either using FPM or Apache's mod_php.
       The the mysqli, GD, curl, json, mbstring, intl, zip and XML extensions
       for PHP should be enabled. We also recommend the posix extension for
       extra debugging information.

<item> MySQL or MariaDB &gt;= 5.5.3 database and client software.

<item> PHP &gt;= 7.0 command line interface and the curl and json
       extensions.

<item> A POSIX compliant shell in <tt>/bin/sh</tt> (e.g. bash or ash).

<item> A statically compiled POSIX shell, located in
       <tt>lib/judge/sh-static</tt> (dash is included for Linux i386/amd64).

<item> <htmlurl name="libcgroup" url="http://libcg.sourceforge.net/">,
       to enable support for Linux cgroup accounting and security on
       the judgehosts. See section <ref id="install_config:judgehost"
       name="installation of a judgehost ">.

<item> A lot of standard (GNU) programs, a probably incomplete list:
       hostname, date, dirname, basename, touch, chmod, cp, mv, cat,
       grep, diff, wc, mkdir, mkfifo, mount, sleep, head, tail, pgrep,
       zip, unzip.

<item> Sudo to gain root privileges.

<item> A LaTeX installation to regenerate the team PDF-manual with
       site specific configuration settings included.
</itemize>

The following items are optional, but may be required to use certain
functionality or are generally useful.
<itemize>

<item> <htmlurl name="phpMyAdmin" url="https://www.phpmyadmin.net/">,
       to be able to access the database in an emergency
       or for data import/export

<item> An NTP daemon (for keeping the clocks between jury
       system and team workstations in sync)

<item> <htmlurl name="libcurl" url="https://curl.haxx.se/libcurl/">
       and <htmlurl name="libJSONcpp" url="https://github.com/open-source-parsers/jsoncpp">
       to use the command line submit client.

<item> <htmlurl name="libmagic" url="https://www.darwinsys.com/file/">
       (for command line submit client to detect binary file submissions)

<item> <htmlurl name="PECL xdiff extension"
        url="https://pecl.php.net/package/xdiff">
       (to reliably make diffs between submissions, DOMjudge will try
        alternative approaches if it is not available)

<item> <htmlurl name="beep" url="http://www.johnath.com/beep/"> for
       audible notification of errors, submissions and judgings, when
       using the default <tt>alert</tt> script.
</itemize>

Software required for building DOMjudge:
<itemize>
<item> gcc and g++ with standard libraries. Other compilers and
       libraries might also work: we have successfully compiled
       DOMjudge sources with <htmlurl name="Clang"
       url="https://clang.llvm.org/"> from the LLVM project; the C
       library should support the POSIX.1-2008 specification.

<item> GNU make
</itemize>

<sect1>Requirements for team workstations
<p>

In the most basic setup the team workstations only need (next to the tools
needed for program development) a modern web browser. We support all
versions of Firefox, Chrome and Edge.

<chapt>Installation and configuration <label id="install_config">
<p>
This chapter details a fresh installation of DOMjudge. The first
section is a Quick Installation Reference, but that should only be
used by those already acquainted with the system. A detailed guide
follows after that.


<sect>Quick installation
<p>
<em>Note:</em> this is not a replacement for the thorough installation
instructions below, but more a cheat-sheet for those who've already
installed DOMjudge before and need a few hints. When in doubt, always
consult the full installation instruction.


External software:
<itemize>
<item> Install the MySQL- or MariaDB-server and set a root password for it.
<item> Install either nginx or Apache, PHP and (recommended) phpMyAdmin.
<item> Make sure PHP works for the web server and command line scripts.
<item> Install necessary compilers on the judgehosts.
<item> See also <ref id="install_config:package-install"
       name="an example command line for Debian and RedHat">.
</itemize>

DOMjudge:
<itemize>
<item> Extract the source tarball and run
       <tt>./configure [--enable-fhs|--prefix=&lt;basepath&gt;] --with-baseurl=&lt;url&gt;</tt>.
<item> Run <tt>make domserver judgehost docs</tt> or just those
       targets you want installed on the current host.
<item> Run <tt>make install-{domserver,judgehost,docs}</tt>
       as root to install the system.
</itemize>
On the domserver host:
<itemize>
<item> Install the MySQL database using e.g. <tt>bin/dj_setup_database -u root -r
       install</tt> on the domserver host.
<item> For Apache: add <tt>etc/apache.conf</tt> to your Apache configuration, edit
       it to your needs, reload web server:<newline>
       <tt>
       sudo ln -s &lt;INSTALL_PATH&gt;/domserver/etc/apache.conf /etc/apache2/conf-available/domjudge.conf &&
       sudo a2enmod rewrite &&
       sudo a2enconf domjudge &&
       sudo apache2ctl graceful
       </tt>
<item> For nginx: add <tt>etc/nginx-conf</tt> to your nginx configuration and add <tt>etc/domjudge-fpm.conf</tt>
       to your PHP FPM pool directory, edit it to your needs, reload web server:<newline>
       <tt>
       sudo ln -s &lt;INSTALL_PATH&gt;/domserver/etc/nginx-conf /etc/nginx/sites-enabled/domjudge &&
       sudo ln -s &lt;INSTALL_PATH&gt;/domserver/etc/domjudge-fpm.conf /etc/php/7.0/fpm/pool.d/domjudge.conf &&
       sudo service nginx reload
       </tt>

<item> Check that the web interface works (/team, /public and /jury).
<item> Check that the API (/api) works and create credentials for the judgehosts.
<item> Create teams, user accounts and add useful contest data through
       the jury web interface or with phpMyAdmin.
<item> Run the config checker in the jury web interface.
</itemize>
On the judgehosts:
<itemize>
<!-- NOTE: update this, then also update the copy of this under chapter 2.14 -->
<item> <tt>useradd -d /nonexistent -U -M -s /bin/false domjudge-run</tt>
<item> Add to <tt>/etc/sudoers.d/</tt> or append to <tt>/etc/sudoers</tt> the
       sudoers configuration as in <tt>etc/sudoers-domjudge</tt>.
<item> Set up cgroup support: enable kernel parameters in
       <tt>/etc/default/grub</tt> and reboot, then use
       <tt>misc/create_cgroups</tt> to create cgroups for DOMjudge.
<item> Put the right credentials in the file <tt>etc/restapi.secret</tt>
       on all judgehosts (copied from the domserver).
<item> Start the judge daemon: <tt>bin/judgedaemon</tt>
</itemize>
It should be done by now. As a check that (almost) everything works,
the set of test sources can be submitted:
<code>
cd tests
make check
</code>
Note that this requires some configuration depending on the
<tt>AUTH_METHOD</tt> selected in <tt>etc/domserver-config.php</tt>,
see <ref id="install_config:submitclient" name="submit client configuration">
for more details.

Then, in the main jury web interface, select the admin link
<it>judging verifier</it> to automatically verify most of the
test sources, except for a few with multiple possible outcomes; these
have to be verified by hand. Read the test sources for a description of
what should (not) happen.

Optionally:
<itemize>
<item> Install the submit client on the team workstations.
<item> Start the balloon notification daemon: <tt>cd bin; ./balloons</tt>;
       or use the balloon web interface.
<item> On the judgehosts, create a pre-built chroot tree:<newline>
       <tt>sudo bin/dj_make_chroot [optional arguments]</tt><newline>
       <tt>$EDITOR lib/judge/chroot-startstop.sh</tt><newline>
       Modifying <tt>chroot-startstop.sh</tt> is typically not
       necessary, but might be in circumstances where your
       interpreters are not installed under <tt>/usr</tt> or require
       files from other locations. See also the section
       <ref id="install_config:judgehost:chroot"
        name="creating a chroot environment">.
<item> For additional features in the jury web interface, the
       following PHP extensions can be installed:
       <itemize>
       <item>xdiff PECL extension for diffs between submissions;
       </itemize>
</itemize>



<sect>Prerequisites
<p>
For a detailed list of the hardware and software requirements,
please refer to the previous chapter on contest planning.

<label id="install_config:package-install">
<sect1>Debian and RedHat installation commands
<p>

For your convenience, the following command will install needed
software on the DOMjudge server as mentioned above when using Debian
GNU/Linux, or one of its derivate distributions like Ubuntu.

<code>
sudo apt install gcc g++ make zip unzip mariadb-server \
	apache2 php php-cli libapache2-mod-php php-zip \
	php-gd php-curl php-mysql php-json php-xml php-intl php-mbstring \
	acl bsdmainutils ntp phpmyadmin python-pygments \
	libcgroup-dev linuxdoc-tools linuxdoc-tools-text \
	groff texlive-latex-recommended texlive-latex-extra \
	texlive-fonts-recommended texlive-lang-european
# To enable the command-line submit client, also add:
sudo apt install libcurl4-gnutls-dev libjsoncpp-dev libmagic-dev
# Replace apache2 and libapache2-mod-php with nginx, php-fpm and
# apache2-utils for nginx
</code>
Note that PHP modules may need to be enabled depending on your distribution.
E.g. on Ubuntu run <code>sudo phpenmod json</code> to enable the JSON module.

The following command can be used on RedHat Enterprise Linux, and
related distributions like CentOS and Fedora.
<code>
sudo yum install gcc gcc-c++ make zip unzip mariadb-server \
	httpd php-gd php-cli php-intl php-mbstring php-mysql php-xml \
	python-pygments ntp linuxdoc-tools libcgroup-devel \
	texlive-collection-latexrecommended texlive-wrapfig
# To enable the command-line submit client, also add:
sudo yum install libcurl-devel jsoncpp-devel file-devel
</code>
Note that the TeX Live packages <tt>expdlist</tt>, <tt>moreverb</tt>,
and <tt>svn</tt> still have be installed manually to rebuild the team
manuals. Furthermore, <tt>phpmyadmin</tt> is available from the
<htmlurl name="Fedora EPEL repository"
url="https://fedoraproject.org/wiki/EPEL">.
The package <tt>jsoncpp-devel</tt> is available in Fedora, but not in
RHEL/CentOS.

Libmagic is not strictly required, but highly recommended for
detecting binary file submissions. Pass the option
<tt>--enable-static-linking</tt> to configure so that these libraries
are statically linked into the <tt>submit</tt> binary and not needed
on the team workstations where <tt>submit</tt> is installed.


On a judgehost, the following should be sufficient. The last two lines show some
example compilers to install for C, C++, Java (OpenJDK), Haskell and Pascal;
change the list as appropriate.

For Debian:
<code>
sudo apt install make sudo debootstrap libcgroup-dev lsof \
	php-cli php-curl php-json php-xml php-zip procps \
	gcc g++ openjdk-8-jre-headless \
	openjdk-8-jdk ghc fp-compiler
</code>

For RedHat:
<code>
sudo yum install make sudo libcgroup-devel lsof \
	php-cli php-mbstring php-xml php-process procps-ng \
	gcc gcc-c++ glibc-static libstdc++-static \
	java-1.7.0-openjdk-headless java-1.7.0-openjdk-devel \
	ghc-compiler fpc
</code>
Note that <tt>fpc</tt> is not available in RedHat 7.


<sect>Installation system
<label id="install_config:installsystem">
<p>

There is a separate <em>maintainer installation</em> method meant for
those wishing to do development on the DOMjudge source code. See
the <ref id="appendix:developerinfo" name="appendix with developer information">
and skip the rest of this section.

The DOMjudge build/install system consists of a <tt>configure</tt>
script and makefiles, but when installing it, some more care has to be
taken than simply running '<tt>./configure &amp;&amp; make &amp;&amp;
make install</tt>'. DOMjudge needs to be installed both on the server
and on the judgehosts. These require different parts of the complete
system to be present and can be installed separately. Within the build
system these parts are referred to as <tt>domserver, judgehost</tt>
and additionally <tt>docs</tt> for all documentation.


DOMjudge can be installed with two different directory layouts:
<descrip>
<tag>Single directory tree</tag>
	With this method all DOMjudge related files and programs are
	installed in a single directory tree which is specified by the
	prefix option of configure, like
<code>
./configure --prefix=$HOME/domjudge --with-baseurl=https://domjudge.example.com/
</code>
	This will install each of the <tt>domserver, judgehost,
	docs</tt> parts in a subdirectory
	<tt>$HOME/domjudge/domserver</tt> etc. These
	subdirectories can be overridden from the defaults with options
	like <tt>--with-domserver_root=DIR</tt>, see <tt>configure
	--help</tt> for a complete list. The prefix defaults to
	<tt>/opt/domjudge</tt>.

	Besides the installed files, there will also be directories
	for logging, temporary files, submitted sources and judging
	data:
	<descrip>
		<tag><tt>log</tt></tag> contains all log files.
		<tag><tt>tmp</tt></tag> contains temporary files.
		<tag><tt>submissions</tt></tag>
		(optionally) on the domserver contains all correctly
		submitted files: as backup only, the database is the
		authoritative source. Note that this directory must be
		writable by the web server for this feature to work.
		<tag><tt>judgings</tt></tag>
		location on judgehosts where submissions are tested,
		each in its own subdirectory.
	</descrip>

	This method of installation is the default and probably most
	practical for normal purposes as it keeps all files together,
	hence easily found.

<tag>FHS compliant</tag>
	This method installs DOMjudge in directories according to the
	<htmlurl name="Filesystem Hierarchy Standard"
	url="http://www.pathname.com/fhs/">. It can be enabled by
	passing the option <tt>--enable-fhs</tt> to <tt>configure</tt>
	and in this case the prefix defaults to <tt>/usr/local</tt>.
	Files will be placed e.g. in <tt>PREFIX/share/domjudge,
	PREFIX/bin, PREFIX/var/log, PREFIX/etc/domjudge</tt>, while
	<tt>/tmp</tt> will be used for temporary files. You may want
	to pass options <tt>--sysconfdir=/etc</tt> and
	<tt>--localstatedir=/var</tt> to <tt>configure</tt> to disable
	the prefix for these.
</descrip>

Note that the <tt>--with-baseurl</tt> configure option is not required
but highly recommended, as it allows building the submit client and
team documentation with the correct URL preset. If needed,
the setting can later be updated in <tt>etc/domserver-static.php</tt>
on the domserver, and in <tt>etc/submit-config.h</tt> in the source
tree for rebuilding the submit client.

After running the <tt>configure</tt> script, the system can be built
and installed. Each of the <tt>domserver, judgehost, docs</tt> parts
can be built and installed separately, respectively by:
<code>
make domserver &amp;&amp; sudo make install-domserver
make judgehost &amp;&amp; sudo make install-judgehost
make docs &amp;&amp; sudo make install-docs
</code>
Note that root privileges are required to set permissions and user and
group ownership of password files and a few directories. If you run
the installation targets as non-root, you will be warned that you have
to perform these steps manually. Although DOMjudge can be installed as
root, one should <em>not</em> run DOMjudge programs and daemons under
the root user, but under a normal user: <tt>runguard</tt> is
specifically designed to be the only part invoked as root (through
sudo) to make this unnecessary. Also, running as root will give rise to
problems, see <ref id="runguard-rootprivs" name="runguard: root privileges not dropped">
in the common problems section.

For a list of basic make targets, run <tt>make</tt> in the source root
directory without arguments.

<sect>Database installation
<p>

DOMjudge uses a MySQL or MariaDB database server for information storage.
Where this document talks about MySQL, it can be understood to also apply
to MariaDB.

The database structure and privileges are included in MySQL
dump files in the sql subdirectory. The default database name is
<tt>domjudge</tt>. This can be changed manually in the
<tt>etc/dbpasswords.secret</tt> file: the database name as specified
in this file will be used when installing.

Installation of the database is done with <tt>bin/dj_setup_database</tt>.
For this, you need an installed and configured MySQL server and
administrator access to it. Run
<code>
dj_setup_database genpass
dj_setup_database [-u <mysql admin user>] [-p <password>|-r] install
</code>
This first creates the DOMjudge database credentials file
<tt>etc/dbpasswords.secret</tt> (optionally change the random
generated password, although it is not needed for normal operation).
Then it creates the database and user and inserts some
default/example data into the domjudge database. The option
<tt>-r</tt> will prompt for a password for mysql; when no user is
specified, the mysql client will try to read
credentials from <tt>$HOME/.my.cnf</tt> as usual. The command
<tt>uninstall</tt> can be passed to <tt>dj_setup_database</tt> to
remove the DOMjudge database and users; <em>this deletes all data!</em>

The script also creates the initial "admin" user with password
stored in <tt>etc/initial_admin_password.secret</tt>.

The domjudge database contains a number of tables, some of which need
to be manually filled with data before the contest can be run. See the
<ref id="contestsetup:database" name="database section of Contest
setup"> for details.

<sect1>Setting up replication or backups
<p>
The MySQL server is the central place of information storage for
DOMjudge. Think well about what to do if the MySQL
host fails or loses your data.

A very robust solution is to set up a replicating MySQL server on
another host. This will be a hot copy of all data up to the second,
and can take over immediately in the event of failure. The MySQL manual
has more information about setting this up.

Alternatively, you can make regular backups of your data to another host,
for example with <tt>mysqldump</tt>, or using a RAID based system.

Replication can also be used to improve performance, by directing all
select-queries to one or more replicated slave servers, while updates
will still be done to the master. This is not supported out of the box,
and will require making changes to the DOMjudge source.

<sect1>Storage of submissions
<label id="install_config:storage_submissions">
<p>
The database is the authoritative version for submission source files;
file system storage is available as an easy way to access the source
files and as backup, but only when the web server has write
permissions to <tt>&lt;domjudge_submitdir&gt;</tt>. File system
storage is ignored if these permissions are not set. The programs
<tt>bin/save_sources2file</tt> and <tt>bin/restore_sources2db</tt> are
available to store and recover the submission table in the database
to/from these files.


<sect>Web server configuration
<p>

For the web interface, you need to have a web server (e.g. nginx or Apache)
installed on the domserver and made sure that PHP correctly works
with it. Refer to the documentation of your web server and PHP for
details.

To configure the Apache web server for DOMjudge, use the Apache
configuration snippet from <tt>etc/apache.conf</tt>. It contains
examples for configuring the DOMjudge pages with an alias directive,
or as a virtualhost, optionally with SSL; it also contains PHP and security
settings. Reload the web server for changes to take effect.
<verb>
ln -s &lt;DOMSERVER_INSTALL_PATH&gt;/etc/apache.conf /etc/apache2/conf-available/domjudge.conf
a2enmod rewrite
a2enconf domjudge
# Edit the file /etc/apache2/conf-available/domjudge.conf to your needs
service apache2 reload
</verb>

An nginx webserver configuration snippet is also provided
in <tt>etc/nginx-conf</tt>. Furthermore the file <tt>etc/domjudge-fpm.conf</tt>
contains the PHP FPM configuration you can use. You still need <tt>htpasswd</tt>
from <tt>apache2-utils</tt> though. To use this configuration
file, perform the following steps
<verb>
ln -s &lt;DOMSERVER_INSTALL_PATH&gt;/etc/nginx-conf /etc/nginx/sites-enabled/domjudge
ln -s &lt;DOMSERVER_INSTALL_PATH&gt;/etc/domjudge-fpm.conf /etc/php/7.0/fpm/pool.d/domjudge.conf
# Edit the files /etc/nginx/sites-enabled/domjudge and
# /etc/php/7.0/fpm/pool.d/domjudge.conf to your needs
service php7.0-fpm reload
service nginx reload
</verb>

The judgehosts connect to DOMjudge via the DOMjudge API so need
to be able to access at least this part of the web interface.

<sect>Fine tuning server settings
<p>
For Apache, there are countless documents on how to maximize performance.
Of particular importance is to ensure that the <tt>MaxClients</tt> setting
is high enough to receive the number of parallel requests you expect, but
not higher than your amount of RAM allows.
Furthermore, we recommend to turn <tt>KeepAlive</tt> off, or at
least make sure that <tt>KeepAliveTimeout</tt> is set to only a few
seconds. Otherwise, a large number of page view requests from teams
and public can easily exhaust the Apache workers, resulting in an
unresponsive website, which will also affect the judgedaemons.

<p>
As for PHP, the use of an opcode cache like the Alternative PHP Cache
(Debian package: <tt>php-apc</tt>) is beneficial for performance. For
uploading large testcases, see the
<ref id="problems:memory" name="section about memory limits">.

<p>
It may be desirable or even necessary to fine tune some MySQL default settings:

<itemize>
<item><tt>max_connections</tt>: The default 100 is too low, because of the
connection caching by Apache threads. 1000 is more appropriate.
<item><tt>max_allowed_packet</tt>: The default of 16MB might be too
low when using large testcases. This should be changed both in the
MySQL server and client configuration and be set to about twice the
maximum testcase size.
<item><tt>innodb_log_file_size</tt>: The default of 48MB might be too
low on MySQL servers with version 5.6.20 or newer due to changes to
the redo log. You should set it 10 times higher than the maximum
testcase size.
<item>Root password: MySQL does not have a password for the root user
by default. It's very desirable to set one.
<item>When maximising performance is required, you can
consider to use the <em>Memory</em> table storage engine
for the scorecache and rankcache tables. They will be
lost in case of a full crash, but can be recalculated from the jury
interface.
</itemize>

<sect>Installation of a judgehost<label id="install_config:judgehost">
<p>

Some extra steps have to be taken to completely install and
configure a judgehost.

<sect1>Unprivileged user and group

<p>
For running solution programs under a non-privileged user, a user and group have
to be added to the system(s) that act as judgehost. This user does not
need a home-directory or password, so the following command would
suffice to add a user and group `domjudge-run' with minimal privileges.

<!-- NOTE: update this, then also update the copy of this under chapter 2.1 -->
<p>
On Debian and Redhat based Linux distributions use:
<verb>
useradd -d /nonexistent -U -M -s /bin/false domjudge-run
</verb>

<p>
For other systems check the specifics of your useradd command.
This user must also be configured as the user under which programs run
via <tt>configure --enable-runuser=USER</tt>; the default is
<tt>domjudge-run</tt>. By default the group is set to the same, this
can be modified with the option <tt>--enable-rungroup=GROUP</tt>

<sect1>Sudo permissions

<p>
<tt>Runguard</tt> needs to be able to become root for certain operations
like changing to the runuser and performing a chroot. Also, the default
<tt>chroot-startstop.sh</tt> script uses sudo to gain privileges for
certain operations. There's a pregenerated <tt>/etc/sudoers.d/</tt> snippet
in <tt>etc/sudoers-domjudge</tt> that contains all required rules. You can
put the lines in the snippet at the end of  <tt>/etc/sudoers</tt>, or, for
modern sudo versions, place the file in <tt>/etc/sudoers.d/</tt>. If you
change the user you run the judgedaemon as, or the installation paths, be
sure to update the sudoers rules accordingly.

<sect1>Creating a chroot environment
<label id="install_config:judgehost:chroot">

<p>
The judgedaemon executes submissions inside a chroot environment for
security reasons. By default it mounts parts of a prebuilt chroot tree
read-only during this judging process (using the script
<tt>lib/judge/chroot-startstop.sh</tt>). This is needed to support
extra languages that require access to interpreters or support
libraries at runtime, for example Java, C#, and any interpreted
languages like Python, Perl, Shell script, etc.

<p>
This chroot tree can be built using the script
<tt>bin/dj_make_chroot</tt>. On Debian and Ubuntu the same
distribution and version as the host system are used, on other Linux
distributions the latest stable Debian release will be used to build
the chroot. Any extra packages to support languages can be passed with
the option <tt>-i</tt> or be added to the <tt>INSTALLDEBS</tt>
variable in the script. The script <tt>bin/dj_run_chroot</tt> runs an
interactive shell or a command inside the chroot. This can be used for
example to install new or upgrade existing packages inside the chroot.
Run these scripts with option <tt>-h</tt> for more information.

Finally, if necessary edit the script <tt>lib/judge/chroot-startstop.sh</tt>
and adapt it to work with your local system. In case you changed the
default pre-built chroot directory, make sure to also update the sudo
rules and the <tt>CHROOTORIGINAL</tt> variable in <tt>chroot-startstop.sh</tt>.

When using the default <tt>chroot-start-stop.sh</tt> script, a static
POSIX shell has to be available for copying it into the chroot
environment. For Linux i386, a static Dash shell is included, which
works out of the box, also for the Linux Intel/AMD 64 architecture.
For other architectures or operating systems, a shell has to be added
manually. Then simply point the <tt>lib/sh-static</tt> symlink to this
file.

<sect1>Linux Control Groups

<p>
DOMjudge uses Linux Control Groups or cgroups for process isolation in
the judgedaemon. Linux cgroups give more accurate measurement of
actually allocated memory than traditional resource limits (which is
helpful with interpreters like Java that reserve but not actually use
lots of memory). Also, cgroups are used to restrict network access so
no separate measures are necessary, and they allow running multiple
judgedaemons on a multi-core machine by using CPU binding.

<p>
The judgedaemon needs to run a recent Linux kernel (at least 3.2.0). The
following steps configure cgroups on Debian wheezy. Instructions for other
distributions may be different (send us your feedback!).
Edit grub config to add cgroup memory and swap accounting to the boot
options. Edit <tt>/etc/default/grub</tt> and change the default
commandline to
<verb>GRUB_CMDLINE_LINUX_DEFAULT="quiet cgroup_enable=memory swapaccount=1"</verb>
Then run <tt>update-grub</tt> and reboot.
After rebooting check that <tt>/proc/cmdline</tt> actually contains the
added kernel options. On VM hosting providers such as Google Cloud or
DigitalOcean, <tt>GRUB_CMDLINE_LINUX_DEFAULT</tt> may be overwritten
by other files in <tt>/etc/default/grub.d/</tt>.

<p>
You have now configured the system to use cgroups, but you need to create
the actual cgroups that DOMjudge will use. For that, you can use the
script under <tt>misc-tools/create_cgroups</tt>. Edit the script to
match your situation first. This script needs to be re-run after each
boot (it has already been added to the judgedaemon init script).

<sect1>REST API credentials

<p>
The judgehost connects to the domserver via a REST API. You need to
create an account for the judgedaemons to use (this may be a
shared account between all judgedaemons) with a difficult,
random password and the 'judgehost' role. On each judgehost, copy from
the domserver (or create) a file <tt>etc/restapi.secret</tt> containing the id, URL,
username and password whitespace-separated on one line, for example:
<verb>default http://example.edu/domjudge/api/  judgehosts  MzfJYWF5agSlUfmiGEy5mgkfqU</verb>
Note that the password must be identical to that of
the <tt>judgehost</tt> user in the admin web interface.
Multiple lines may be specified to allow a judgedaemon to work for multiple
domservers. The id is used to differentiate between multiple domservers,
and should be unique within the <tt>restapi.secret</tt> file.

<sect1>Starting the judgedaemon

<p>
Finally start the judgedaemon (optionally binding it to CPU core X):
<code>bin/judgedaemon [-n X]</code>
If using the <tt>-n X</tt> option, then an extra user
<tt>domjudge-run-X</tt> must also be created.
Additionally, you could add a kernel parameter <tt>isolcpus=X</tt>
to make the Linux kernel not schedule any processes on CPU X,
except those explicitly bound to it. This might improve runtime
consistency under some circumstances; however, in a test running a
single judgedaemon on 6 CPU core machines, we did not see any
significant improvement of runtime or decrease in variations.

<p>
Upon its first connection to the domserver API, the judgehost will be
auto-registered and will be by default enabled. If you wish to
add a new judgehost but have it initially disabled, you can add it
manually through the DOMjudge web interface and set it to disabled
before starting the judgedaemon.

<sect>Building and installing the submit client<label id="install_config:submitclient">
<p>

DOMjudge supports two submission methods: via the command
line <tt>submit</tt> program and via the web interface. From
experience, both methods have users that prefer the one above the
other.

The command line submit client sends submissions using the API
interface internally. This requires the libcURL and libjsonCPP library
development files at compile time. The submit client can be statically
linked using the <tt>--enable-static-linking</tt> configure option to
avoid a runtime dependency.

The submit client can be built with <tt>make submitclient</tt>. There
is no make target to install the submit client, as its location will
very much depend on the environment. You might e.g. want to copy it to
all team computers or make it available on a network filesystem. Note
that if the team computers run a different (version of the) operating
system than the jury systems, then you need to build the submit
client for that OS.

The submit client needs to know the URL of the domserver. This
can be passed as a command line option or environment variable. The
latter option makes for easier usage. A sample script
<tt>submit_wrapper.sh</tt> is included, which sets this variable.
See that script for more details on how to set this up.

The submit client authenticates to the DOMjudge API via either the
configured authentication scheme, or can use the DOMjudge internal
username and password combination for a given user account regardless
of authentication scheme. For example, when the IPADDRESS scheme is
used, no additional configuration is required because submissions
will come from the correct IP address of the team. When another
scheme is used, it may be necessary to place username and password
combinations in the team's account so the submit client can use
those. In this case these are always the DOMjudge internal
password, so not e.g. LDAP passwords when using that scheme. The
credentials are placed in the file <tt>~/.netrc</tt>, with example
content:
<verb>machine domserver.example.com login user0123 password Fba^2bHzz</verb>
See the netrc(4) manual page for more details.
You may want to distribute those <tt>.netrc</tt> files in advance
to the team accounts. Make sure they are only readable for the
user itself.

<sect1>The submit client under Windows/Cygwin
<p>

<em>Note: this feature is not well supported anymore; we
recommend using the web interface for submitting in Windows.</em>

<p>
The submit client can also be built under Windows when the Cygwin
environment is installed. First install <url name="Cygwin"
url="https://cygwin.com/install.html">, and include GCC, curl-devel
and maybe some more packages.
When Cygwin is correctly installed with all necessary development
tools, the submit binary can be created by running <tt>configure</tt>
followed by <tt>make submit.exe</tt> in the <tt>submit</tt> directory.


<sect>Configuration
<p>
Configuration of the judge system is mostly done by editing the
configuration variables on the page <tt>Configuration settings</tt>
available in the administrator interface, and changes take effect
immediately. The administrator interface can be reached
on <tt>http(s)://yourhost.example.edu/domjudge/jury/</tt> and the
default username is <tt>admin</tt> with initial password stored in
<tt>etc/initial_admin_password.secret</tt>.

Some settings that are tightly coupled to the filesystem can be
configured in the files in <tt>etc</tt>: <tt>domserver-config.php,
judgehost-config.php, common-config.php</tt> for the configuration
options of the domserver, judgehost and shared configuration options
respectively. Descriptions of settings are included in these files.
The judgedaemon must be restarted for changes to take effect, while
these are directly picked up by the webinterfaces.

Besides these settings, there are a few other places where changes can
be made to the system, see <ref id="install_config:configurablescripts"
name="other configurable scripts">.

<sect>Authentication Methods<label id="install_config:authmethods">
<p>
Out of the box users are able to authenticate using basic username and password.
There is also a configuration option to allow teams to self-register with the system.
<p>Two other authentication methods are available:

<itemize>
<item>IP Address - authenticates users based on the IP address they are accessing
the system from
<item>X-Headers - authenticates users based on some http X-HEADER's
</itemize>

<sect1>IP Address
<p>To enable the IP Address authentication method, you will need to edit
the database configuration option <tt>auth_methods</tt> to include <tt>ipaddress</tt>.
<p>Once this is done, when a user first logs in their IP Address will be
associated with their account, and subsequent logins will allow them to log
in without authenticating.
<p>If desired, you can edit the IP Address associated with an account from the
Users page in the jury interface.

<sect1>X-Headers
<p><p>To enable the IP Address authentication method, you will need to edit
the database configuration option <tt>auth_methods</tt> to include <tt>xheaders</tt>.

<p>To use this method, the following headers need to be sent to the
<tt>/login</tt> URL. This can be done using the squid proxy for example, to
prevent teams from needing to know their own log in information but in an
environment where IP address based auth is not feasible(multi site over the
internet contest).
<itemize>
<item><tt>X-DOMjudge-Login</tt> - Contains the username
<item><tt>X-DOMjudge-Pass</tt>  - Contains the user's password, base64 encoded
</itemize>

Squid configuration for this might look like:
<code>
acl autologin url_regex ^http://localhost/domjudge/login
request_header_add X-DOMjudge-Login "$USERNAME" autologin
request_header_add X-DOMjudge-Pass "$BASE64_PASSWORD" autologin
</code>

<sect>Executables
<p>

DOMjudge supports executable archives (uploaded and stored in ZIP
format) for configuration of languages, special run and compare
programs. The archive must contain an executable file named
<tt>build</tt> or <tt>run</tt>. When deploying a new (or changed)
executable to a judgehost <tt>build</tt> is executed <em>once</em> if
present. Afterwards an executable file <tt>run</tt> must exist (it may
have existed before), that is called to execute the compile, compare,
or run script. The specific formats are detailed below.

Executables may be changed via the web interface in an online editor
or by uploading a replacement zip file. Changes apply immediately to
all further uses of that executable.

<sect>Configuration of languages
<p>

Compilers can be configured by creating or selecting/editing an executable in
the web interface. When compiling a set of source files, the <tt>run</tt>
executable is invoked with the following arguments: destination file name,
memory limit (in KB), main (first) source file, other source files.
For more information, see for example the executables <tt>c</tt> or
<tt>java_javac_detect</tt> in the web interface. Note that compile
scripts are included for most common languages already.

Interpreted languages and non-statically linked binaries (for example,
Oracle Java) can in principle also be used, but require that all
runtime dependencies are added to the chroot environment. See section
<ref id="install_config:judgehost:chroot" name="creating a chroot environment">.

Interpreted languages do not generate an executable and in principle
do not need a compilation step. However, to be able to use interpreted
languages (also Oracle's Java), during the compilation step a script
must be generated that will function as the executable: the script
must run the interpreter on the source. See for example <tt>pl</tt>
and <tt>java_javac_detect</tt> in the list of executables.

<sect>Configuration of special run and compare programs
<p>

To allow for problems that do not fit within the standard scheme of
fixed input and/or output, DOMjudge has the possibility to change the
way submissions are run and checked for correctness.

The back end script <tt>testcase_run.sh</tt> that handles
the running and checking of submissions, calls separate programs
for running submissions and comparison of the results. These can be
specialised and adapted to the requirements per problem. For this, one
has to create executable archives as described above.
Then the executable must be
selected in the <tt>special_run</tt> and/or <tt>special_compare</tt>
fields of the problem (an empty value means that the default run and
compare scripts should be used; the defaults can be set in the global
configuration settings). When creating custom run and compare
programs, we recommend re-using wrapper scripts that handle the
tedious, standard part. See the boolfind example for details.

<sect1>Compare programs
<p>

Compare scripts/programs should follow the
<htmlurl name="Kattis/problemarchive output validator format"
url="http://www.problemarchive.org/wiki/index.php/Output_validator">.
DOMjudge uses the <htmlurl name="default output validator"
url="http://www.problemarchive.org/wiki/index.php/Problem_Format#Output_Validators">
specified there as its default, which can be found at
<url url="https://github.com/Kattis/problemtools/blob/master/support/default_validator/">.

Note that DOMjudge only supports a subset of the functionality
described there. In particular, the calling syntax is
<code>
/path/to/compare_script/run &lt;testdata.in&gt; &lt;testdata.ans&gt; &lt;feedbackdir&gt; &lt;compare_args&gt; &lt; &lt;program.out&gt;
</code>
where <tt>testdata.in</tt> <tt>testdata.ans</tt> are the jury
reference input and output files, <tt>feedbackdir</tt> the directory
containing e.g. the judging response file <tt>judgemessage.txt</tt> to
be written to (the only other permitted files there
are <tt>teammessage.txt score.txt judgeerror.txt diffposition.txt</tt>),
<tt>compare_args</tt> a list of arguments that can set when
configuring a contest problem, and <tt>program.out</tt> the team's
output. The validator program should not make any assumptions on its
working directory.

For more details on writing and modifying a compare (or validator)
scripts, see the <tt>boolfind_cmp</tt> example and the comments at the
top of the file <tt>testcase_run.sh</tt>.

<sect1>Run programs
<p>

Special run programs can be used, for example, to create an interactive
problem, where the contestants' program exchanges information with a
jury program and receives data depending on its own output. The
problem <tt>boolfind</tt> is included as an example interactive
problem, see <tt>docs/examples/boolfind.pdf</tt> for the description.

Usage is similar to compare programs: you can either create a program
<tt>run</tt> yourself, or use the provided wrapper script, which
handles bi-directional communication between a jury program and the
contestants' program on stdin/stdout (see the <tt>run</tt>
file in the <tt>boolfind_run</tt> executable).

For the first case, the calling syntax that the program must accept is
equal to the calling syntax of <tt>run_wrapper</tt>, which is
documented in that file. When using <tt>run_wrapper</tt>, you should
copy it to <tt>run</tt> in your executable archive.
The jury must write a program named exactly <tt>runjury</tt>,
accepting the calling syntax
<code>
runjury <testdata.in> <program.out>
</code>
where the arguments are files to read input testdata from and write
program output to, respectively. This program will communicate via
stdin/stdout with the contestants' program. A special compare program
must probably also be created, so the exact data written to
<tt>&lt;program.out&gt;</tt> is not important, as long as the
correctness of the contestants' program can be deduced from the
contents by the compare program.


<sect>Alerting system
<p>

DOMjudge includes an alerting system. This allows the administrator to
receive alerts when important system events happen, e.g. an error
occurs, or a submission or judging is made.

These alerts are passed to a plugin script <tt>alert</tt> which can
easily be adapted to fit your needs. The default script emits
different beeping sounds for the different messages when the
<tt>beep</tt> program is available, but it could for example also be
modified to send a mail on specific issues, connect to monitoring
software like Nagios, etc. For more details, see the script
<tt>lib/alert</tt>.

<sect>Other configurable scripts<label id="install_config:configurablescripts">
<p>

There are a few more places where some configuration of the system can
be made. These are sometimes needed in non-standard environments.
<itemize>
<item> In <tt>bin/dj_make_chroot</tt> on a judgehost some changes to
       variables can be made, most notably <tt>DEBMIRROR</tt> to
       select a Debian mirror site near you.
<item> The script <tt>lib/judge/chroot-startstop.sh</tt> can be
       modified to suit your local environment. See comments in that
       file for more information.
</itemize>

<sect>Logging &amp; debugging
<p>

All DOMjudge daemons and web interface scripts support logging and
debugging in a uniform manner via functions in <tt>lib.error.*</tt>.
There are three ways in which information is logged:
<itemize>
<item>Directly to <tt>stderr</tt> for daemons or to the web page for
      web interface scripts (the latter only on serious issues).
<item>To a log file set by the variable <tt>LOGFILE</tt>, which is set
      in each program. Unsetting this variable disables this method.
<item>To syslog. This can be configured via the <tt>SYSLOG</tt>
      configuration variable in <tt>etc/common-config.php</tt>. This
      option gives the flexibility of syslog, such as remote logging.
      See the syslog(daemon) documentation for more information.
      Unsetting this variable disables this method.
</itemize>
Each script also defines a default threshold level for messages to be
logged to stderr (<tt>VERBOSE</tt>: defaults to <tt>LOG_INFO</tt> in
daemons and <tt>LOG_ERR</tt> in the web interface) and for
log file/syslog (<tt>LOGLEVEL</tt>: defaults to <tt>LOG_DEBUG</tt>).

In case of problems, it is advisable to check the logs for clues.
Extra debugging information can be obtained by setting the config
option <tt>DEBUG</tt> to a bitwise-or of the available
<tt>DEBUG_*</tt> flags in <tt>etc/common-config.php</tt>, to e.g.
generate extra SQL query and timing information in the web interface.

<sect>(Re)generating documentation and the team manual
<p>

There are three sets of documentation available under the <tt>doc</tt>
directory in DOMjudge:
<descrip>
<tag>the admin-manual</tag>
for administrators of the system (this document),
<tag>the judge-manual</tag>
for judges, describing the jury web interface and giving some general
information about this system,
<tag>the team-manual</tag>
for teams, explaining how to use the system and what restrictions
there are.
</descrip>

<p>
The team manual is only available in PDF format and must be built from
the LaTeX sources in <tt>doc/team</tt> after configuration of the
system. A prebuilt team manual is included, but note that it contains
default/example values for site-specific configuration settings such
as the team web interface URL and judging settings such as the memory
limit. We strongly recommend rebuilding the team manual to include
site-specific settings and also to revise it to reflect your contest
specific environment and rules.

<p>
Besides a standard LaTeX installation, the team manual
requires the <tt>svn</tt> and <tt>expdlist</tt> packages. These are
available in TeX Live in the <tt>texlive-latex-extra</tt> package in
any modern Linux distribution. Alternatively, you can download and
install them manually from their respective subdirectories in <url
url="http://mirror.ctan.org/macros/latex/contrib">.

<p>
When the <tt>docs</tt> part of DOMjudge is installed and site-specific
configuration set, the team manual can be generated with the command
<tt>genteammanual</tt> found under <tt>docs/team</tt>. The PDF
document will be placed in the current
directory or a directory given as argument.
The following should do it on a Debian-like system:
<code>
sudo apt install make texlive-latex-extra texlive-latex-recommended texlive-lang-european
cd &lt;INSTALL_PATH&gt;/docs/team
./genteammanual [targetdir]
</code>

<p>
The administrator's and judge's manuals are available in PDF and HTML
format and prebuilt from SGML sources. Rebuilding these is not normally
necessary. To rebuild them on a Debian-like system, the following commands
should do it:
<code>
sudo apt install linuxdoc-tools make zip ghostscript groff texlive-latex-recommended
make -C doc/admin docs
make -C doc/judge docs
</code>


<sect>Optional features <label id="optionalfeatures">
<p>

<sect1>Multiple judgedaemons per machine
<p>
You can run multiple judgedaemons on one multi-cpu or multi-core
machine, dedicating one cpu core to each judgedaemon.

To that end, add extra unprivileged users to the system, i.e. add users
<tt>domjudge-run-&lt;X&gt;</tt> (where <tt>X</tt> runs through
<tt>0,1,2,3</tt>) with <tt>useradd</tt> as described in section <ref
id="install_config:judgehost" name="installation of a judgehost">.
Finally, start each of the judgedaemons with
<code>
judgedaemon -n <X>
</code>
to bind it to core X.

<sect1>Encrypted communications (HTTPS) <label id="https">
<p>

DOMjudge can be configured to run on HTTPS, so teams and judgedaemons
communicate with the domserver securely over encrypted SSL/TLS connections.
Setting up SSL for Apache is documented in the
<htmlurl url="http://httpd.apache.org/docs/2.4/ssl/" name="Apache manual">
and in many tutorials around the web.

<p>
The judgedaemons must recognise the CA you're using, otherwise they will
refuse to connect over HTTPS. If your judgedaemon gives an error message
about an untrusted certificate, put your domserver's certificate in
<tt>/etc/ssl/certs/yourname.crt</tt> of each judgehost (and on the team
machines when using the commandline submit client) and run:
<code>sudo c_rehash</code>

<p>
When loading teams from the ICPC registration system through the import
feature in DOMjudge, the certificate from icpc.baylor.edu must similarly
be accepted by your local installation or if not, added via the procedure
above.

<sect1>NTP time synchronisation
<p>

We advise to install an NTP-daemon (Network Time Protocol) to make
sure the time between domserver, judgehosts, and jury and team
computers is in sync.

<sect1>Printing
<p>

It is recommended to configure the local desktop printing of team
workstations where ever possible: this has the most simple interface
and allows teams to print from within their editor.

<p>
If this is not feasible, DOMjudge includes support for printing via
the DOMjudge web interface: the DOMjudge server then needs to be
able to deliver the uploaded files to the printer. It can be
enabled via the <tt>enable_printing</tt> configuration option in
the administrator interface. By default printouts are formatted with
<tt>enscript</tt> and and printed with local <tt>lpr</tt>.
The exact command used to send the files to a printer can be
changed by overriding the <tt>send</tt> method of the
<tt>\App\Utils\Printing</tt> class.

<sect1>Judging consistency
<p>

The following issues can be considered to improve consistency in
judging.

<itemize>
<item> Disable CPU frequency scaling and Intel "Turbo Boost" to
prevent fluctuations in CPU power.
<item> Disable address-space randomization to make programs with
memory addressing bugs give more reproducible results. To do that,
you can add the following line to <tt>/etc/sysctl.conf</tt>:
<code>
kernel.randomize_va_space=0
</code>
This will restore these settings permanently across reboots.
Then run the following command:
<code>
sudo sysctl -p
</code>
to directly activate these settings.
</itemize>


<sect>Upgrading
<p>

There is some support to upgrade DOMjudge to newer versions. Note that
this functionality is not extensively tested, so when you plan to
upgrade, <em>you are strongly advised to backup the DOMjudge database
and other data before continuing</em>. We also advise to check the
<tt>ChangeLog</tt> file for important changes.

Upgrading the filesystem installation is probably best done by
installing the new version of DOMjudge in a separate place and
transferring the configuration settings from the old version.

There are SQL upgrade scripts to transform the database including its
data to the layout of a newer version. The scripts can be found under
<tt>sql/upgrade</tt> and each script applies changes between two
consecutive DOMjudge versions. At the beginning of each script, a check
is performed which will let MySQL bail out with an error if it should
not be applied anymore. Note that the scripts must be applied in order
(sorted by release). These scripts can be applied by running
<tt>dj_setup_database upgrade</tt>. Be aware that these scripts are
conservative in adding and upgrading SQL data, so check that e.g. new
compile scripts are present or add them manually, and check the
upgrade scripts manually for any other data upgraded.

If you have any active contests, it may be advisable to run
"Refresh scoreboard cache" from the DOMjudge web interface after
the upgrade.

<chapt>Setting up a contest <label id="contestsetup">
<p>

After installation is successful, you want to run your contest!
Configuring DOMjudge to run a contest (or a number of them, in
sequence) involves the following steps:

<itemize>
<item> Configure the contest data;
<item> Set up authentication for teams;
<item> Supply in- and output testdata;
<item> Check that everything works.
</itemize>

<sect>Configure the contest data
<label id="contestsetup:database">
<p>

DOMjudge stores and retrieves most of its data from the MySQL
database. Some information must be filled in beforehand, other tables
will be populated by DOMjudge.

You can use the jury web interface to add, edit and delete most types
of data described below. It's advised to keep a version of phpMyAdmin
handy in case of emergencies, or for general database operations like
import and export.

This section describes the meaning of each table and what you need to
put into it. Tables marked with an `x' are the ones you have to
configure with contest data before running a contest (via the jury web
interface or e.g. with phpMyAdmin), the other tables are used
automatically by the software:
<tabular ca="cll">
 |auditlog         |Log of every state-changing event.@
 |balloon          |Balloons to be handed out.@
 |clarification    |Clarification requests/replies are stored here.@
x|configuration    |Runtime configuration settings.@
x|contest          |Contest definitions with start/end time.@
x|contestproblem   |Coupling of problems to contests and data specific to it.@
x|contestteam      |Coupling of teams to contests.@
 |event            |Log of events during contests.@
x|executable       |Executable compile/run/compare scripts.@
 |internal&lowbar;error|Stores errors that occurred on judgehosts including logs.@
 |judgehost        |Computers (hostnames) that function as judgehosts.@
x|judgehost&lowbar;restriction|Optional restriction sets on submissions taken by judgehosts.@
 |judging          |Judgings of submissions.@
 |judging&lowbar;run      |Result of one testcase within a judging.@
x|language         |Definition of allowed submission languages.@
x|problem          |Definition of problems (name, timelimit, etc.).@
 |rankcache        |Cache of team ranking data for public/teams and for the jury.@
 |rejudging        |Metadata for batched rejudging.@
 |role             |Possible user roles.@
 |scorecache       |Cache of the scoreboards for public/teams and for the jury.@
 |submission       |Submission metadata of solutions to problems.@
 |submission&lowbar;file  |Submitted code files.@
x|team             |Definition of teams.@
x|team&lowbar;affiliation |Definition of institutions a team can be affiliated with.@
x|team&lowbar;category    |Different category groups teams can be put in.@
 |team&lowbar;unread      |Records which clarifications are read by which team.@
x|testcase         |Definition of testdata for each problem.@
x|user             |Users that will able to access the system.@
x|userrole         |Mapping of users to their roles.
</tabular>

Now follows a longer description (including fields) per table that has
to be filled manually. As a general remark: almost all tables have an
identifier field. Most of these are numeric and automatically
increasing; these do not need to be specified. The tables
<tt>executable</tt> and <tt>language</tt> have text strings as identifier
fields. These need to be manually specified and only alpha-numeric, dash and
underscore characters are valid, i.e. <tt>a-z, A-Z, 0-9, -, &lowbar;</tt>.

<descrip>
<tag>configuration</tag>
This table contains configuration settings.
These entries are simply stored as <tt>name, value</tt> pairs, where
the values are JSON encoded, <tt>type</tt> contains the allowed data
type, and <tt>description</tt> documents the configuration setting.

<tag>contest</tag>
The contests that the software will run. E.g. a test session and the
live contest.

<tt>cid</tt> is the reference ID and <tt>contestname</tt> is a
descriptive name used in the interface, while <tt>shortname</tt> is
the publicly visible identifier.

<tt>activatetime</tt>, <tt>starttime</tt> and <tt>endtime</tt>
are required fields and specify when this contest is active and
open for submissions. Optional <tt>freezetime</tt> and
<tt>unfreezetime</tt> control scoreboard freezing and
<tt>deactivatetime</tt> when the contest is not visible anymore.
For a detailed treating of these, see section <ref
id="contestsetup:milestones" name="Contest milestones">.
All contest times can be specified relative to <tt>starttime</tt>,
except of course <tt>starttime</tt> itself. The input given in the
jury interface (either relative or absolute) is stored in the
<tt>*time_string</tt> fields, while a calculated absolute version is
stored in the fields without the <tt>_string</tt> suffix.

The <tt>public</tt> field can be used to limit which contests are
displayed as public scoreboards (as opposed to privately to a selected
set of teams), while <tt>enabled</tt> can be used to (temporarily)
disable a contest altogether.

<tag>contestproblem</tag>
This table couples problems to contests: <tt>cid</tt> and
<tt>probid</tt> describe the pairing.

Furthermore, it stores problem data that is specific for the included
contest: <tt>shortname</tt> is a contest-unique identifier string for
the problem, <tt>points</tt> defaults to 1 and can be set to assign
non-even scoring; <tt>allow_submit</tt> determines whether teams can submit
solutions for this problem. Non-submittable problems are also not
displayed on the scoreboard. This can be used to define spare
problems, which can then be added to the contest quickly;
<tt>allow_judge</tt> determines whether judgehosts will judge
submissions for this problem. See also the explanation for language.

The <tt>color</tt> tag can be filled with a CSS colour specification
to associate with this problem; see also section <ref id="scoreboard:colours"
name="Scoreboard: colours">.

<tag>contestteam</tag>
This table couples teams to contests. Teams can only submit solutions to
problems in contests that are public or which they are part of.

<tag>executable</tag>
This table stores zip-bundles of executable scripts that can be used
as compile, run, and compare scripts.

<tag>judgehost&lowbar;restriction</tag>
This table encodes restriction sets for selecting which submissions
are sent to a judgehost. The restrictions are JSON encoded in
the <tt>restrictions</tt> column, and can be set in the admin web
interface to restrict on specific contests, problems, languages, and
to never rejudge on the same judgehost. A restriction set can be
assigned to judgehost(s) on the edit page of the judgehosts overview.

<tag>language</tag>
Programming languages in which to accept and judge submissions.
<tt>langid</tt> is a string of maximum length 8, which references the
language.
<tt>name</tt> is the displayed name of the language;
<tt>extensions</tt> is a JSON encoded list of recognized filename extensions;
<tt>allow_submit</tt> determines whether teams can submit
using this language; <tt>allow_judge</tt> determines whether
judgehosts will judge submissions for this problem. This can for
example be set to <em>no</em> to temporarily hold judging when a problem occurs
with the judging of a specific language; after resolution of the
problem this can be set to <em>yes</em> again.

<tt>time_factor</tt> is the relative factor by which the timelimit is
multiplied for solutions in this language; <tt>compile_script</tt>
refers to a compile executable script that is used for this language.

<tag>problem</tag>
This table contains the problem definitions. <tt>probid</tt> is the
reference ID, <tt>cid</tt> is the contest ID this problem is (only)
defined for: a problem cannot be used in multiple contests.
<tt>name</tt> is the full name (description) of the problem.

<tt>allow_submit</tt> determines whether teams can submit
solutions for this problem. Non-submittable problems are also not
displayed on the scoreboard. This can be used to define spare
problems, which can then be added to the contest quickly;
<tt>allow_judge</tt> determines whether judgehosts will judge
submissions for this problem. See also the explanation for language.

<tt>timelimit</tt> is the timelimit in seconds
within which solutions for this problem have to run (taking into
account <tt>time_factor</tt> per language). See also
<ref id="problems:timelimits" name="enforcement of time limits"> for
more details.

<tt>memlimit</tt> is the memory limit in kB allotted for this problem.
If empty then the global configuration setting <tt>memory_limit</tt>
is used. Equivalently for <tt>outputlimit</tt>.

<tt>special_run</tt> if not empty defines a custom run program
<tt>run_&lt;special_run&gt;</tt> to run compiled submissions for
this problem and <tt>special_compare</tt> if not empty defines a
custom compare program <tt>compare_&lt;special_compare&gt;</tt> to
compare output for this problem.

The <tt>color</tt> tag can be filled with a CSS colour specification
to associate with this problem; see also section <ref id="scoreboard:colours"
name="Scoreboard: colours">.

In <tt>problemtext</tt> a PDF, HTML or plain text document can be
placed which allows team, public and jury to download the problem
statement. Note that no additional filtering takes place, so HTML
(and PDF to some extent) should be from a trusted source to prevent
cross site scripting or other attacks. The file type is stored in
<tt>problemtext_type</tt>.

<tag>team</tag>
Table of teams: <tt>teamid</tt> is (internal) ID of the team,
while <tt>externalid</tt> can be used to store an ID for im/exporting
to other systems.
<tt>name</tt> the displayed name of the team, <tt>categoryid</tt> is
the ID of the category the team is in; <tt>affilid</tt> is the
affiliation ID of the team.

When <tt>enabled</tt> is set to 0, the team immediately disappears from
the scoreboards and cannot use the team web interface anymore, even
when already logged in. One use case could be to disqualify a team on
the spot.

<tt>members</tt> are the names of the team members, separated by
newlines and <tt>room</tt> is the location or room of the team, both for
display only; <tt>comments</tt> can be filled with arbitrary useful
information and is only visible to the jury.

The <tt>penalty</tt> field can be used to give this team a (positive
or negative) number of penalty minutes to correct for exceptional
circumstances.

<tag>team_affiliation</tag>
<tt>affilid</tt> is the reference ID and <tt>name</tt> the name of the
institution. <tt>country</tt> should be the 3 character
<htmlurl name="ISO 3166-1 alpha-3 abbreviation"
url="http://en.wikipedia.org/wiki/ISO_3166-1_alpha-3#Officially_assigned_code_elements">
of the country and <tt>comments</tt> is a free form field
that is displayed in the jury interface.

A country flag can be displayed on the scoreboard. For this to work,
the <tt>country</tt> field must match a (flag) picture in
<tt>webapp/public/images/countries/&lt;country&gt;.png</tt>. All
country flags are present there, named with their 3-character ISO
codes. See also <tt>webapp/public/images/countries/README</tt>.

<tag>team_category</tag>
<tt>categoryid</tt> is the reference ID and <tt>name</tt> is a string:
the name of the category. <tt>sortorder</tt> is the order at which
this group must be sorted in the scoreboard, where a higher number
sorts lower and equal sort depending on score.

The <tt>color</tt> is again a CSS colour specification used to
discern different categories easily. See also section <ref
id="scoreboard:colours" name="Scoreboard: colours">.

The <tt>visible</tt> flag determines whether teams in this category
are displayed on the public/team scoreboard. This feature can be used
to remove teams from the public scoreboard by assigning them to a
separate, invisible category.

<tag>testcase</tag>
The testcase table contains testdata for each problem;
<tt>testcaseid</tt> is a unique identifier, <tt>input</tt> and
<tt>output</tt> contain the testcase input/output and <tt>image</tt>
an optional graphical representation of the testcase for the jury.
The fields <tt>md5sum_input</tt>, <tt>md5sum_output</tt>,
and <tt>md5sum_image</tt> contain their respective md5
hashes to check for up-to-date-ness of cached versions by the
judgehosts and <tt>image_thumb</tt> and <tt>image_type</tt> a
thumbnail version and mimetype string for the image.
The field <tt>probid</tt> is the corresponding problem and
<tt>rank</tt> determines the order of the testcases for one problem.
<tt>description</tt> is an optional description for this testcase. See
also <ref id="contestsetup:testdata" name="providing testdata">.

<tag>user</tag>
This table has the users that the system knows about with their
login credentials. Each user may have one or more roles, like
being part of a team, being a jury member or administrator.
There are also functional accounts, like for judgedaemons.

</descrip>

<sect>Contest milestones<label id="contestsetup:milestones">
<p>

The <tt>contest</tt> table specifies timestamps for each contest
that mark specific milestones in the course of the contest.

The triplet <em>activatetime</em>, <em>starttime</em> and <em>endtime</em>
define when the contest runs and are required fields (activatetime and
starttime may be equal).

activatetime is the moment when a contest first becomes
visible to the public and teams . Nothing can be submitted yet and the
problem set is not revealed. Clarifications can be viewed and sent.

At starttime, the scoreboard is displayed and submissions are accepted.
At endtime the contest stops. New incoming submissions will still be
processed and judged, but the result will not be shown anymore to teams;
they instead receive the verdict`too-late'. Unjudged submissions received
before endtime will still be judged normally.

<em>freezetime</em> and <em>unfreezetime</em> control scoreboard
freezing. freezetime is the time after which the public and team
scoreboard are not updated anymore (frozen). This is meant to make the
last stages of the contest more thrilling, because no-one knows who has
won. Leaving them empty disables this feature. When using this feature,
unfreezetime can be set to automatically `unfreeze' the scoreboard at
that time. For a more elaborate description, see also section <ref
id="scoreboard:freeze" name="Scoreboard: freezing and defrosting">.

The scoreboard, results and clarifications will remain to be displayed
to team and public after a contest, until the <em>deactivatetime</em>.

All events happen at the first moment of the defined time. That is:
for a contest with starttime "12:00:00" and endtime "17:00:00", the
first submission will be accepted at 12:00:00 and the last one at
16:59:59.

The following ordering must always hold: activatetime &lt;= starttime
&lt; (freezetime &lt;=) endtime (&lt;= unfreezetime) (&lt;= deactivatime).

<sect>Providing testdata
<label id="contestsetup:testdata">
<p>
Testdata is used to judge the problems: when a submission run is given the
input testdata, the resulting output is compared to the reference
output data using a <em>compare script</em>. The default compare
script simply checks if the outputs are equal up to whitespace
differences, but more elaborate comparisons can be done, see e.g.
the <tt>float</tt> and <tt>boolfind_cmp</tt> scripts.

The database has a separate table named testcase, which can be manipulated
from the web interface. Under a problem, click on the testcase link. There
the files can be uploaded. The judgehosts cache a copy based on MD5 sum, so if
you need to make changes later, re-upload the data in the web interface and
it will automatically be picked up.

Testdata can also be imported into the system from a problem zip file,
following the <htmlurl name="Kattis problem package format"
url="http://www.problemarchive.org/wiki/index.php/Problem_Format">.

<!-- FIXME: rewrite this
Testcases will be added to those already present and imported
properties will overwrite those in the database. A completely new
problem can also be imported from a zip-bundle on the problems
overview webpage; in that case, note that if the file
<tt>domjudge-problem.ini</tt> is not present, a default value is
chosen for the unmodifiable primary key <tt>probid</tt> (as well as
for the other keys). It is possible to upload multiple zip
files in one go, each of which will be added as a separate
problem.
-->

<sect>Start the daemons
<p>

Once everything is configured, you can start the daemons.
They all run as a normal user on the system. The needed root privileges
are gained through sudo only when necessary.

<itemize>
<item> One or more judgedaemons: one on each judgehost (or optionally
  multiple per host; then the <tt>-n X</tt> option should be used to
  bind a judgedaemon to CPU X to prevent CPU resource conflicts).
<item> Optionally the balloon notification daemon (as an alternative
  to the web interface).
</itemize>

<sect>Check that everything works
<p>

If the daemons have started without any problems, you've come a long
way! Now to check that you're ready for a contest.

First, go to the jury interface:
<tt>http(s)://yourhost.example.edu/domjudge/jury</tt>. Look under all
the menu items to see whether the displayed data looks sane. Use the
config-checker under `Admin Functions' for some sanity checks on your
configuration.

Go to a team workstation and see if you can access the team page and
if you can submit solutions.

Next, it is time to submit some test solutions. If you have the default
Hello World problem enabled, you can submit some of the example sources
from under the <tt>doc/examples</tt> directory. They should give `CORRECT'.

You can also try some (or all) of the sources under
<tt>tests</tt>. Use <tt>make check</tt> to submit a variety of
tests; this should work when the submit client is available and the
default example problems are in the active contest. There's also
<tt>make stress-test</tt>, but be warned that these tests might crash
a judgedaemon. The results can be checked in the web interface; each
source file specifies the expected outcome with some explanations. For
convenience, there is a link <it>judging verifier</it> in the admin
web interface; this will automatically check whether submitted sources
from the <tt>tests</tt> directory were judged as expected. Note that a
few sources have multiple possible outcomes: these must be verified
manually.

When all this worked, you're quite ready for a contest. Or at least,
the practice session of a contest.

<sect>Testing jury solutions
<p>

Before running a real contest, you and/or the jury will want to test
the jury's reference solutions on the system.

The simplest way to do this is to include the jury solutions in a
problem zip file and upload this. You can also upload a zip file
containing just solutions to an existing problem. Note that the zip
archive has to adhere to the <htmlurl name="Kattis problem package format"
url="http://www.problemarchive.org/wiki/index.php/Problem_Format">.
For this to work, the jury/admin who uploads the problem has to have
an associated team to which the solutions will be assigned. The
solutions will automatically be judged if the contest is active (but
it need not have started yet). You can verify whether the submissions
gave the expected answer from the link on the jury/admin index page.


<chapt>Team Workstations<label id="teamworkstations">
<p>

Here's a quick checklist for configuring the team workstations. Of course,
when hosting many teams, it makes sense to generate a preconfigured account that
has these features and can be distributed over the workstations.

<enum>
<item> The central tool teams use to interact with DOMjudge is the web browser.
  <itemize>
  <item> If possible, set the Home Page to <tt>your.domjudge.location/team/</tt>
  <item> Go to the team page and check if this team is correctly identified.
  <item> If using https and a self signed certificate, add this certificate
         to the browser certificate list to prevent annoying dialogs.
  </itemize>
<item> Make sure compilers for the supported languages are installed and working.
<item> Provide teams with the command line submit client and check that it works.
  <itemize>
  <item> If needed, set environment variables to configure the client.
  <item> Optionally distribute <tt>.netrc</tt> files with team credentials.
  <item> If using https and a self signed certificate, add this certificate
         to the local trust store (see <ref id="https" name="HTTPS setup">).
  </itemize>
<item> Make the sample in- and output data from the problem set available.
<item> Add your SSH key to their authorized_keys file, so you can always access
their account for wiping and emergencies.
<item> Check that internet access is blocked.
</enum>

<chapt>Web interface<label id="webinterface">
<p>

The web interface is the main point of interaction with the system.
Here you can view submissions coming in, control judging,
view the standings and edit data.

<sect>Jury and Administrator view
<p>

The jury interface has two possible views: one for jury members,
and one for DOMjudge administrators. The second view is the same as
the jury view, but with more features added, and can be enabled by
giving a user the 'admin' role (instead of or next to the 'jury' role).

This separation is handy as a matter of security (jury members cannot
(accidentally) modify things that shouldn't be) and clarity (jury members
are not confused / distracted by options they don't need).

Options offered to administrators only:
<itemize>
<item>Adding and editing any contest data
<item>Managing team passwords
<item>The config checker
<item>Refreshing the scoreboard & hostname caches
<item>Rejudge 'correct' submissions
<item>Restart 'pending' judgings
</itemize>
Furthermore, some quick link menu items might differ according to
usefulness for jury or admins.

<em>A note on rejudging:</em> it is policy within the DOMjudge system
that a correct solution cannot be reverted to incorrect. Therefore,
administrator rights are required to rejudge correct or pending
(hence, possibly correct) submissions. For some more details on
rejudging, see the jury manual.


<sect>The scoreboard <label id="scoreboard">
<p>

The scoreboard is the canonical overview for anyone interested in the
contest, be it jury, teams or the general public. It deserves to get a
section of its own.

<sect1>Colours and sorting <label id="scoreboard:colours">
<p>

Each problem can be associated with a specific colour, e.g. the colour
of the corresponding balloon that is handed out. DOMjudge can display
this colour on the scoreboard, if you fill in the `color' attribute in
the `problem' table; set it to a <htmlurl name="valid CSS colour value"
url="http://www.w3.org/TR/REC-CSS1#color-units"> (e.g. `green'
or `#ff0000', although a name is preferred for displaying colour
names).

It's possible to have different categories of teams participating,
this is controlled through the `team_category' table. Each category
has its own background colour in the scoreboard. This colour can be
set with the `color' attribute to a valid CSS colour value.

If you wish, you can also define a sortorder in the category table.
This is the first field that the scoreboard is sorted on. If you want
regular teams to be sorted first, but after them you want to sort both
spectator- and business teams equally, you define `0' for the regular
category and `1' for the other categories. To completely remove a
category from the public (but not the jury) scoreboard, the category
visible flag can be set to `0'.


<sect1>Starting and ending
<p>

A contest can be selected for viewing after its activation time, but
the scoreboard will only become visible to public and teams once the
contest starts. Thus no data such as problems and teams is revealed
before then.

When the contest ends, the scores will remain displayed until the
deactivation time passes.

<sect1>Freezing and defrosting <label id="scoreboard:freeze">
<p>

DOMjudge has the option to `freeze' the public- and team scoreboards
at some point during the contest. This means that scores are no longer
updated and remain to be displayed as they were at the time of the
freeze. This is often done to keep the last hour interesting for all.
The scoreboard freeze time can be set with the `freezetime'
attribute in the contest table.

The scoreboard freezing works by looking at the time a submission is
made. Therefore it's possible that submissions from (just) before the
freezetime but judged after it can still cause updates to the public
scoreboard. A rejudging during the freeze may also cause such updates.

If you do not set any freeze time, this option does nothing. If you
set it, the public and team scoreboards will not be updated anymore
once this time has arrived. The jury will however still see the actual
scoreboard.

Once the contest is over, the scores are not directly `unfrozen'.
This is done to keep them secret until e.g. the prize ceremony. You
can release the final scores to team and public interfaces when the
time is right. You can do this either by setting a predefined
`unfreezetime' in the contest table, or you push the `unfreeze
now' button in the jury web interface, under contests.

<sect1>Clickability
<p>

Almost every cell is clickable in the jury interface and gives
detailed information relevant to that cell. This is (of course) not
available in the team and public scoreboards, except that in the team
and public interface the team name cell links to a page with some more
information and optionally a team picture, and the problem header
cells link to the problem text, if available.

<sect1>Caching
<p>

The scoreboard is not recalculated on every page load, but rather
cached in the database. It should be safe for repeated reloads from
many clients. In exceptional situations (should never occur in normal
operation, e.g. a bug in DOMjudge), the cache may become inaccurate.
The jury administrator interface contains an option to recalculate a
fresh version of the entire scoreboard. You should use this option
only when actually necessary, since it puts quite a load on the
database.

<sect1>Exporting to an external website
<p>

In many cases you might want to create a copy of the scoreboard for
external viewing from the internet. Just for that, the public interface
can be called with the url parameter <tt>?static=1</tt>. It produces
a version of the scoreboard with refresh meta-tags, login facilities
and links to team pages removed. This can for example be requested
every minute via <tt>curl</tt> and the output be placed as static
content on a publicly reachable webserver.

<sect>Balloons
<p>

In many contests balloons are handed out to teams that solve a
particular problem. DOMjudge can help in this process: both a web
interface and a notification daemon are available to notify that a new
balloon needs to be handed out. Note that only one should be used at a
time.

The web based tool is reachable from the main page in the jury
interface, where each balloon has to be checked off by the person
handing it out.

For the daemon, set the <tt>BALLOON_CMD</tt> in
<tt>etc/domserver-config.php</tt> to define how notifications
are sent. Examples are to mail to a specific mailbox or to send
prints to a printer. When configured, start <tt>bin/balloons</tt>
and notification will start.

Notifications will stop as soon as the scoreboard is frozen.
Enable the <tt>show_balloons_postfreeze</tt> configuration option to
keep issuing balloon notifications after the freeze.


<chapt>Security <label id="security">
<p>

This judging system was developed with security as one of the main
goals in mind. To implement this rigorously in various aspects
(restricting team access to others and the internet, restricting
access to the submitted programs on the domjudge systems, etc...)
requires root privileges to different parts of the whole contest
environment. Also, security measures might depend on the environment.
Therefore we have decided not to implement security measures which are
not directly related to the judging system itself. We do have some
suggestions on how you can setup external security.

<sect>Considerations
<p>

Security considerations for a programming contest are a bit different
from those in normal conditions: normally users only have to be
protected from deliberately harming each other. During a contest we
also have to restrict users from cooperatively communicating,
accessing restricted resources (like the internet) and restrict user
programs running on judgehosts.

We expect that chances are small that people are trying to cheat
during a programming contest: you have to hack the system and make use
of that within very limited time. And you have to not get caught and
disqualified afterwards. Therefore passive security measures of
warning people of the consequences and only check (or probe) things
might be enough.

However we wanted the system to be as secure as possible within
reason. Furthermore this software is open source, so users can try to
find weak spots before the contest.

<sect>Internal security <label id="security:internal">
<p>

Internal security of the system relies on users not being able to get
to any vital data (jury input/output and users' solutions). Data is
stored in two places: in files on the DOMjudge system account and in
the SQL database.

Files should be protected by restricting permission to the relevant
directories.

<em>Note:</em> the database password is stored in
<tt>etc/dbpasswords.secret</tt>. This file has to be
non-readable to teams, but has to be readable to the web server to let
the jury web interface work. A solution is to make it readable to a
special group the web server runs as. This is done when using the
default configuration and installation method and when <tt>make
install-{domserver,judgehost}</tt> is run as root. The webserver group
can be set with <tt>configure --with-webserver-group=GROUP</tt>; by
default it is tried to be determined from groups available on the
system, e.g. <tt>www-data</tt> or <tt>apache</tt>.

Judgehosts and the domserver communicate with each other over HTTP.
Also all parties accessing the domserver web interface obviously use
this protocol. We advise to setup HTTPS so interactions between domserver,
judgehosts and teams are all protected. If you need to use a self-signed
certificate, you can consider to install it on the team workstations
beforehand to minimize hassle.

When using IP address authentication, one has to be careful that teams
are not able to spoof their IP (for which they normally need
root/administrator privileges), as they would then be able to view
other teams' submission info (not their code) and clarifications and
submit as that team.
<em>Note:</em> This means that care has to be taken e.g. that teams
cannot simply login onto one another's computer and spoof their identity.

Problem texts can be uploaded to DOMjudge. No filtering is performed
there, so make sure they are from trusted sources to, in the
case of HTML, prevent cross site scripting code to be injected.

<sect>Root privileges <label id="security:rootprivs">
<p>

A difficult issue is the securing of submitted programs run by the
jury. We do not have any control over these sources and do not want to
rely on checking them manually or filtering on things like system
calls (which can be obscured and are different per language).

Therefore we decided to tackle this issue by running these programs in
a environment as restrictive as possible. This is done by setting up a
minimal chroot environment with Linux cgroup process control. For
this, root privileges on the judgehosts and statically compiled
programs are needed. By also limiting all kinds of system resources
(memory, processes, time, unprivileged user and network access) we
protect the system from programs which try to hack or could crash the
system.

<sect>File system privileges <label id="security:fileprivs">
<p>

Of course you must make sure that the file system privileges are set
such that there's no unauthorised access to sensitive data, like
submitted solutions or passwords. This is quite system dependent. At
least <tt>&lt;judgehost_judgedir&gt;</tt> should not be readable by other users
than DOMjudge.

<sect1>Permissions for the web server <label id="security:webprivs">
<p>

The default installation sets permissions correctly for the web
server user (commonly <tt>www-data</tt> or <tt>apache</tt>).
The following information is for those who want to verify the setup
or make modifications to the settings.

Care should be taken with the <tt>etc</tt> directory: the
<tt>domserver-{config,static}.php</tt>, <tt>dbpasswords.secret</tt>
and <tt>restapi.secret</tt> files should all be readable, but
<tt>dbpasswords.secret</tt> and <tt>restapi.secret</tt> should not be
readable by anyone else. This can be done for example by setting the
<tt>etc</tt> directory to owner:group &lt;DOMjudge
account&gt;:&lt;Web server group&gt; and permissions
<tt>drwxr-x---</tt>, denying users other than yourself and the
web server group access to the configuration and password files.

If you want the web server to also store incoming submission sources on
the file system (next to the database), then <tt>&lt;domserver_submitdir&gt;</tt> must be
writable for the web server, see also <ref
id="install_config:storage_submissions" name="storage of submissions">.

<sect>External security <label id="security:external">
<p>

The following security issues are <em>not</em> handled by DOMjudge,
but left to the administrator to set up.

Network traffic between team computers, domserver and the internet
should be limited to what is allowed. Possible ways of enforcing this
might be: monitor traffic, modify firewall rules on team computers or
(what we implemented with great satisfaction) put all team computers
behind a firewalling router.

Solutions are run within a restricted (chroot/cgroup) environment on
the judgehosts which restricts outgoing network access.

<appendix>

<chapt>Common problems and their solutions <label id="problems">
<p>

<sect>The Java virtual machine (jvm) and memory limits
<p>

DOMjudge imposes memory limits on submitted solutions. These limits
are imposed before the compiled submissions are started. On the other
hand, the Java virtual machine is started via a compile-time generated
script which is run as a wrapper around the program. This means that
the memory limits imposed by DOMjudge are for the jvm and the running
program within it. As the jvm uses approximately 300MB, this reduces
the limit by this significant amount. See the <tt>java_javac</tt> and
<tt>java_javac_detect</tt> compile executable scripts for the
implementation details.

If you see error messages of the form
<code>
Error occurred during initialization of VM
java.lang.OutOfMemoryError: unable to create new native thread
</code>
or
<code>
Error occurred during initialization of VM
Could not reserve enough space for object heap
</code>
Then the problem is probably that the jvm needs more memory than what is
reserved by the Java compile script. You should try to increase the
<tt>MEMRESERVED</tt> variable in the java compile executable and check that
the configuration variable <tt>memory limit</tt> is set larger than
<tt>MEMRESERVED</tt>. If that does not help, you should try to increase the
configuration variable <tt>process limit</tt> (since the JVM uses a lot of
processes for garbage collection).

Note that (especially on x86_64 machines) the jvm seems to preallocate
huge amounts of memory, up to 2 GB! This is not actually all used, but
the memory restriction in DOMjudge will flag it as such, unless Linux
cgroups are enabled, then the actual memory used is measured. Thus, we
strongly recommend using Linux cgroups when using the Oracle jvm.

<sect>Java class naming
<p>

Java requires a specific naming of the main class. When declaring the
main class <tt>public</tt>, the filename must match the class name.
Therefore one should <em>not</em> declare the main class public; from
experience however, many teams do so. Secondly, the Java compiler
generates a bytecode file depending on the class name. There are two
ways to handle this.

The simplest Java compile script <tt>java_javac</tt>
requires the main class to be named <tt>Main</tt> with method
<code>
public static void main(String args[])
</code>

The alternative (and default) is to use the script
<tt>java_javac_detect</tt>, which automatically detects the
main class and even corrects the source filename when it is declared
public.

<sect>Memory limit errors in the web interface<label id="problems:memory">
<p>

When uploading large testdata files, one can run into an error in
the jury web interface of the form:
<verb>
Fatal error: Allowed memory size of XX bytes exhausted (tried to
allocate YY bytes) in /home/domjudge/system/lib/lib.database.php
on line 154
</verb>
This means that the PHP engine has run out of memory. The solution is
to raise the memory limits for PHP. This can be done by either editing
<tt>etc/apache.conf</tt> and raising the <tt>memory_limit</tt>,
<tt>upload_max_filesize</tt> and <tt>post_max_size</tt> values to well
above the size of your largest testcase. You can change these parameters
under the jury directory or by directly editing the global Apache or
<tt>php.ini</tt> configuration. Note also that <tt>max_file_uploads</tt>
must be larger than the maximum number of testcases per problem to be
able to upload and edit these in the web interface.

The optional PHP Suhosin module may also impose additional limits; check
your error logging to see if these are triggered. You may also need to
raise MySQL's <tt>max_allowed_packet</tt> parameter in
<tt>/etc/mysql/my.cnf</tt> on both server and client.

<sect>Compiler errors: `runguard: root privileges not dropped'
<label id="runguard-rootprivs">
<p>

<verb>
Compiling failed with exitcode 255, compiler output:
/home/domjudge/system/bin/runguard: root privileges not dropped
</verb>
When the above error occurs on submitting any source, this indicates
that you are running the <tt>judgedaemon</tt> as root user. You should
not run any part of DOMjudge as root; the parts that require it will
gain root by themselves through sudo. Either run it as yourself or,
probably better, create dedicated a user <tt>domjudge</tt> under
which to install and run everything.

Also do not confuse this with the <tt>domjudge-run</tt> user:
this is a special user to run submissions as and should also not
be used to run normal DOMjudge processes; this user is only for
internal use.

<sect>found processes still running ... apport<label id="problems:apport">
<p>

<verb>
error: found processes still running as 'domjudge-run', check manually:
2342 apport
</verb>
The above error occurs on submitting segmentation fault solutions if you have
apport installed (which is default on Ubuntu).
Disable or uninstall the apport daemon on all judgehosts.

<sect>Enforcement of time limits<label id="problems:timelimits">
<p>

Time limits within DOMjudge are enforced primarily in CPU time, and
secondly a more lax wall clock time limit is used to make sure that
submissions cannot idle and hog judgedaemons. The way that time limits
are calculated and passed through the system involves a number of
steps, so documented here.

Time limits are set per problem in seconds. Each language in turn may
define a time factor (defaulting to 1) that multiplies it to get a
specific time limit for that problem/language combination. This is
the <em>soft timelimit</em>. The configuration setting <tt>timelimit
overshoot</tt> is then used to calculate a <em>hard timelimit</em>.
This overshoot can be specified in terms of an absolute and relative
margin.

The <tt>soft:hard</tt> timelimit pair is passed
to <tt>testcase_run.sh</tt> and then on to <tt>runguard</tt> as both
wall clock and CPU limit. Since the CPU option is passed second, this
one is used by <tt>runguard</tt> when reporting whether the soft,
actual timelimit has been surpassed. The submitted program gets
killed when either the hard wall clock or CPU time has passed.


<chapt>API <label id="api">
<p>

DOMjudge comes with a fully featured REST API. It is based on the
<htmlurl name="CCS Contest API specification"
         url="https://clics.ecs.baylor.edu/index.php?title=Contest_API">,
to which some DOMjudge-specific API endpoints have been added. Full documentation
on the available API endpoints can be found at
<tt>http(s)://yourhost.example.edu/domjudge/api/doc</tt>. DOMjudge also offers an
<htmlurl name="OpenAPI Specification ver. 2"
         url="https://swagger.io/docs/specification/2-0/basic-structure/">
compatible JSON file, which can be found at
<tt>http(s)://yourhost.example.edu/domjudge/api/doc.json</tt>.


<chapt>Multi-site contests <label id="multisite">
<p>

This manual assumed you are running a singe-site contest; that is, the teams
are located closely together, probably in a single physical location. In a
multi-site or distributed contest, teams from several remote locations use the
same DOMjudge installation. An example is a national contest where teams can
participate at their local institution.

DOMjudge supports such a setup on the condition that a central installation of
DOMjudge is used to which the teams connect over the internet. It is here where
all submission processing and judging takes place. Because DOMjudge uses a web
interface for all interactions, teams and judges will interface with the system
just as if it were local.  Still, there are some specific considerations for a
multi-site contest.

Network: there must be a relatively reliable network connection between the
locations and the central DOMjudge installation, because teams cannot submit or
query the scoreboard if the network is down. Because of traversing an unsecured
network, you may want to consider HTTPS for encrypting the traffic.  If you
want to limit internet access, it must be done in such a way that the remote
DOMjudge installation can still be reached.

Team authentication: the IP-based authentication will still work as long as
each team workstation has a different public IP address. If some teams are
behind a NAT-router and thus all present themselves to DOMjudge with the same
IP-address, another authentication scheme must be used (e.g. PHP sessions).

Judges: if the people reviewing the submissions will be located remotely as
well, it's important to agree beforehand on who-does-what, using the
submissions claim feature and how responding to incoming clarification requests
is handled. Having a shared chat/IM channel may help when unexpected issues
arise.

Scoreboard: by default DOMjudge presents all teams in the same scoreboard.
Per-site scoreboards can be implemented either by using team categories or
team affiliations in combination with the scoreboard filtering option.


<chapt>Developer information
<label id="appendix:developerinfo">
<p>

This section contains instructions specifically for those wishing
to modify the DOMjudge source. If you have any questions about
developing DOMjudge, or if you want to share your changes that
may be useful to others, please don't hesitate to contact us
through <htmlurl name="our development mailing list"
url="https://www.domjudge.org/mailman/listinfo/domjudge-devel">.


<sect>Bootstrapping from Git repository sources
<p>

The installation steps in this document assume that you are using a
downloaded tarball from the DOMjudge website. If you want to install
from Git repository sources, because you want to use the bleeding edge
code or consider to send a patch to the developers, the
configure/build system first has to be bootstrapped.

This requires
additional software to be installed:
<itemize>
<item> The GNU autoconf/automake toolset

<item> Composer - PHP Package Manager.

<item> Linuxdoc and groff to build the admin and judge
       documentation from SGML sources and a LaTeX installation to
       generate the PDF admin, judge and default team manual.
</itemize>

On Debian(-based) systems, the following apt command should
install the additionally required packages (next to the
<ref id="install_config:package-install" name="standard set of packages">):
<code>
sudo apt install autoconf automake git composer
</code>

Composer is packaged since Debian Stretch and Ubuntu Xenial.
Alternatively, it can be installed by following the documentation
located <htmlurl name="here" url="https://getcomposer.org/download">.

When this software is present, bootstrapping can be done by running
<tt>make dist</tt>, which creates the <tt>configure</tt> script,
downloads and installs the PHP dependencies via composer and
generates documentation from SGML/LaTeX sources.

<sect>Maintainer mode installation
<p>

Besides the two modes of installation described in section
<ref id="install_config:installsystem" name="Installation system">,
DOMjudge provides a special maintainer mode installation.
This method does an in-place installation within the source
tree. This allows one to immediately see effects when modifying
code.

This method requires some special steps which can most easily
be run via makefile rules as follows:
<code>
sudo apt install acl
make maintainer-conf [CONFIGURE_FLAGS=&lt;extra options for ./configure&gt;]
make maintainer-install
</code>
Note that these targets have to be executed <em>separately</em> and
they replace the steps described in the section
<ref id="install_config:installsystem" name="Installation system">;
also no <tt>--prefix</tt> flag or other directories have to be
specified to <tt>configure</tt>. In this case the binaries
(e.g. <tt>judgedaemon</tt> and <tt>dj_setup_database</tt>) can be
found in their respective source directories, and are also symlinked
in <tt>bin</tt>.

<sect>Makefile structure
<p>

The Makefiles in the source tree use a recursion mechanism to run make
targets within the relevant subdirectories. The recursion is handled
by the <tt>REC_TARGETS</tt> and <tt>SUBDIRS</tt> variables and the
recursion step is executed in <tt>Makefile.global</tt>. Any target
added to the <tt>REC_TARGETS</tt> list will be recursively called in
all directories in <tt>SUBDIRS</tt>. Moreover, a local variant of the
target with <tt>-l</tt> appended is called after recursing into the
subdirectories, so recursion is depth-first.

The targets <tt>dist, clean, distclean, maintainer-clean</tt> are
recursive by default, which means that these call their local
<tt>-l</tt> variants in all directories containing a Makefile. This
allows for true depth-first traversal, which is necessary to correctly
run the <tt>*clean</tt> targets: otherwise e.g. <tt>paths.mk</tt> will
be deleted before subdirectory <tt>*clean</tt> targets are called that
depend on information in it.


</report>
